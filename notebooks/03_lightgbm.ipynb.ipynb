{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc68bfb-539c-48b2-8dd5-76173a5ec133",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏笏\n",
      "1. Loading and cleaning data...\n",
      "2. Preparing sequence data...\n",
      "3. Splitting data into Tune (60%), Validation (20%), and Test (20%) sets...\n",
      "   Tune set size: 12256\n",
      "   Validation set size: 4086\n",
      "   Test set size: 4086\n",
      "\n",
      "笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武\n",
      "Bake-Off Round 1: Evaluating Expert-Tuned Baseline Model\n",
      "笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武\n",
      "\n",
      "--- Evaluating 'Expert-Tuned LGBM' on the Final Test Set ---\n",
      "  Retraining at test step 0...\n",
      "  Retraining at test step 500...\n",
      "  Retraining at test step 1000...\n",
      "  Retraining at test step 1500...\n",
      "  Retraining at test step 2000...\n",
      "  Retraining at test step 2500...\n",
      "  Retraining at test step 3000...\n",
      "  Retraining at test step 3500...\n",
      "  Retraining at test step 4000...\n",
      "\n",
      "  Tuning classification threshold and calculating all metrics...\n",
      "\n",
      "[Expert-Tuned LGBM] Final Test Set Performance:\n",
      "  Best Threshold = 0.87\n",
      "  F1-Score       = 0.2265\n",
      "  AUC            = 0.5749\n",
      "  G-Mean         = 0.2432\n",
      "  Precision      = 0.1660\n",
      "  Recall         = 0.3563\n",
      "\n",
      "笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武\n",
      "Bake-Off Round 2: Finding and Evaluating Optuna-Tuned Model\n",
      "笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武\n",
      "4. Starting Optuna optimization process...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff6a4b45020746e6a7e049294add3ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optuna process finished!\n",
      "沛 Best F1-score on Validation Set: 0.4265\n",
      "沛 Best Hyperparameters Found: {'n_estimators': 400, 'learning_rate': 0.010268965803862608, 'num_leaves': 146, 'scale_pos_weight': 50}\n",
      "\n",
      "--- Evaluating 'Optuna-Tuned LGBM' on the Final Test Set ---\n",
      "  Retraining at test step 0...\n",
      "  Retraining at test step 500...\n",
      "  Retraining at test step 1000...\n",
      "  Retraining at test step 1500...\n",
      "  Retraining at test step 2000...\n",
      "  Retraining at test step 2500...\n",
      "  Retraining at test step 3000...\n",
      "  Retraining at test step 3500...\n",
      "  Retraining at test step 4000...\n",
      "\n",
      "  Tuning classification threshold and calculating all metrics...\n",
      "\n",
      "[Optuna-Tuned LGBM] Final Test Set Performance:\n",
      "  Best Threshold = 0.33\n",
      "  F1-Score       = 0.2619\n",
      "  AUC            = 0.5669\n",
      "  G-Mean         = 0.2716\n",
      "  Precision      = 0.2071\n",
      "  Recall         = 0.3563\n",
      "\n",
      "笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武笊絶武\n",
      "Bake-Off Complete!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "#\n",
    "# LightGBM Champion Model Bake-Off v3: Full Metrics Evaluation\n",
    "#\n",
    "from __future__ import annotations\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "# 沐･ FIX: Added roc_auc_score for a complete evaluation\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "class LightGBM_Champion_Finder:\n",
    "    def __init__(self, config: Dict[str, Any]):\n",
    "        self.config = config\n",
    "        self.df = self._load_data(config['csv_path'])\n",
    "        self.feat_cols = [c for c in self.df.columns if c not in config['meta_cols']]\n",
    "        self.X_all, self.y_all = self._make_windows()\n",
    "        self.X_tune, self.y_tune, self.X_val, self.y_val, self.X_test, self.y_test = self._split_data()\n",
    "\n",
    "    def _load_data(self, path: str | Path) -> pd.DataFrame:\n",
    "        print(\"笏\" * 60 + \"\\n1. Loading and cleaning data...\")\n",
    "        df = pd.read_csv(path).loc[:, ~pd.read_csv(path).columns.duplicated()]\n",
    "        req = set(self.config['meta_cols'])\n",
    "        if missing := req - set(df.columns): raise KeyError(f\"Missing cols: {missing}\")\n",
    "        df[self.config['quarter_col']] = pd.to_datetime(df[self.config['quarter_col']])\n",
    "        df.sort_values([self.config['id_col'], self.config['quarter_col']], inplace=True)\n",
    "        df = df.dropna()\n",
    "        num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "        return df[list(req | set(num_cols))]\n",
    "\n",
    "    def _make_windows(self) -> (np.ndarray, np.ndarray):\n",
    "        print(\"2. Preparing sequence data...\")\n",
    "        X, y = [], []\n",
    "        cfg = self.config\n",
    "        for _, g in self.df.groupby(cfg['id_col']):\n",
    "            g = g.sort_values(cfg['quarter_col'])\n",
    "            arr, lbl = g[self.feat_cols].to_numpy(), g[cfg['target_col']].to_numpy()\n",
    "            for i in range(cfg['lags'], len(g)):\n",
    "                X.append(arr[i - cfg['lags']:i].ravel())\n",
    "                y.append(lbl[i])\n",
    "        return np.asarray(X), np.asarray(y)\n",
    "\n",
    "    def _split_data(self):\n",
    "        \"\"\"Splits data chronologically into Tune, Validation, and Test sets.\"\"\"\n",
    "        print(\"3. Splitting data into Tune (60%), Validation (20%), and Test (20%) sets...\")\n",
    "        n = len(self.y_all)\n",
    "        tune_end = int(n * 0.6)\n",
    "        val_end = int(n * 0.8)\n",
    "        \n",
    "        X_tune, y_tune = self.X_all[:tune_end], self.y_all[:tune_end]\n",
    "        X_val, y_val = self.X_all[tune_end:val_end], self.y_all[tune_end:val_end]\n",
    "        X_test, y_test = self.X_all[val_end:], self.y_all[val_end:]\n",
    "        \n",
    "        print(f\"   Tune set size: {len(y_tune)}\")\n",
    "        print(f\"   Validation set size: {len(y_val)}\")\n",
    "        print(f\"   Test set size: {len(y_test)}\")\n",
    "        return X_tune, y_tune, X_val, y_val, X_test, y_test\n",
    "\n",
    "    def _objective(self, trial: optuna.Trial) -> float:\n",
    "        \"\"\"The objective function for Optuna to maximize.\"\"\"\n",
    "        params = {\n",
    "            'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1,\n",
    "            'random_state': self.config['seed'],\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 200, 800, step=100),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 1e-2, 0.1, log=True),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "            'scale_pos_weight': trial.suggest_int('scale_pos_weight', 20, 50),\n",
    "        }\n",
    "\n",
    "        scaler = StandardScaler().fit(self.X_tune)\n",
    "        X_tune_std = scaler.transform(self.X_tune)\n",
    "        X_val_std = scaler.transform(self.X_val)\n",
    "        model = lgb.LGBMClassifier(**params).fit(X_tune_std, self.y_tune)\n",
    "        y_probs = model.predict_proba(X_val_std)[:, 1]\n",
    "        \n",
    "        best_f1 = 0\n",
    "        for threshold in np.arange(0.1, 0.9, 0.05):\n",
    "            preds = (y_probs > threshold).astype(int)\n",
    "            best_f1 = max(best_f1, f1_score(self.y_val, preds))\n",
    "            \n",
    "        return best_f1\n",
    "    \n",
    "    def _evaluate_on_test_set(self, params: Dict[str, Any], model_name: str):\n",
    "        \"\"\"\n",
    "        Evaluates a model on the final test set, including full metrics.\n",
    "        \"\"\"\n",
    "        print(f\"\\n--- Evaluating '{model_name}' on the Final Test Set ---\")\n",
    "        win_size, retrain_interval = self.config['sliding_win_size'], self.config['retrain_interval']\n",
    "        X_history = np.vstack([self.X_tune, self.X_val])\n",
    "        y_history = np.concatenate([self.y_tune, self.y_val])\n",
    "        \n",
    "        all_probs, all_trues = [], []\n",
    "        model, scaler = None, None\n",
    "\n",
    "        for i in range(len(self.X_test)):\n",
    "            if model is None or i % retrain_interval == 0:\n",
    "                print(f\"  Retraining at test step {i}...\")\n",
    "                X_train_current = np.vstack([X_history, self.X_test[:i]])\n",
    "                y_train_current = np.concatenate([y_history, self.y_test[:i]])\n",
    "                X_train_window, y_train_window = X_train_current[-win_size:], y_train_current[-win_size:]\n",
    "                \n",
    "                scaler = StandardScaler().fit(X_train_window)\n",
    "                X_train_std = scaler.transform(X_train_window)\n",
    "                model = lgb.LGBMClassifier(**params).fit(X_train_std, y_train_window)\n",
    "\n",
    "            X_test_point = self.X_test[i].reshape(1, -1)\n",
    "            X_test_point_std = scaler.transform(X_test_point)\n",
    "            y_prob = model.predict_proba(X_test_point_std)[:, 1][0]\n",
    "            all_probs.append(y_prob)\n",
    "            all_trues.append(self.y_test[i])\n",
    "            \n",
    "        print(\"\\n  Tuning classification threshold and calculating all metrics...\")\n",
    "        \n",
    "        # Calculate AUC (threshold-independent)\n",
    "        final_auc = roc_auc_score(all_trues, all_probs)\n",
    "        \n",
    "        # Find best F1 and its corresponding P, R\n",
    "        best_f1, best_thresh, best_prec, best_rec = 0, 0, 0, 0\n",
    "        for threshold in np.arange(0.1, 0.9, 0.01):\n",
    "            preds = (np.array(all_probs) > threshold).astype(int)\n",
    "            current_f1 = f1_score(all_trues, preds, zero_division=0)\n",
    "            if current_f1 > best_f1:\n",
    "                best_f1, best_thresh = current_f1, threshold\n",
    "                best_prec = precision_score(all_trues, preds, zero_division=0)\n",
    "                best_rec = recall_score(all_trues, preds, zero_division=0)\n",
    "        \n",
    "        # Calculate G-mean from the best P and R\n",
    "        final_gmean = np.sqrt(best_prec * best_rec) if best_prec > 0 and best_rec > 0 else 0\n",
    "\n",
    "        print(f\"\\n[{model_name}] Final Test Set Performance:\")\n",
    "        print(f\"  Best Threshold = {best_thresh:.2f}\")\n",
    "        print(f\"  F1-Score       = {best_f1:.4f}\")\n",
    "        print(f\"  AUC            = {final_auc:.4f}\")\n",
    "        print(f\"  G-Mean         = {final_gmean:.4f}\")\n",
    "        print(f\"  Precision      = {best_prec:.4f}\")\n",
    "        print(f\"  Recall         = {best_rec:.4f}\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Orchestrates the entire bake-off process.\"\"\"\n",
    "        print(\"\\n\" + \"笊申" * 60)\n",
    "        print(\"Bake-Off Round 1: Evaluating Expert-Tuned Baseline Model\")\n",
    "        print(\"笊申" * 60)\n",
    "        expert_params = self.config['lightgbm_expert_params']\n",
    "        self._evaluate_on_test_set(expert_params, \"Expert-Tuned LGBM\")\n",
    "\n",
    "        print(\"\\n\" + \"笊申" * 60)\n",
    "        print(\"Bake-Off Round 2: Finding and Evaluating Optuna-Tuned Model\")\n",
    "        print(\"笊申" * 60)\n",
    "        print(\"4. Starting Optuna optimization process...\")\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(self._objective, n_trials=self.config['optuna_trials'], show_progress_bar=True)\n",
    "        \n",
    "        print(f\"\\nOptuna process finished!\")\n",
    "        print(f\"沛 Best F1-score on Validation Set: {study.best_value:.4f}\")\n",
    "        print(f\"沛 Best Hyperparameters Found: {study.best_params}\")\n",
    "        \n",
    "        optuna_params = {**self.config['lightgbm_expert_params'], **study.best_params}\n",
    "        self._evaluate_on_test_set(optuna_params, \"Optuna-Tuned LGBM\")\n",
    "        print(\"\\n\" + \"笊申" * 60)\n",
    "        print(\"Bake-Off Complete!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    CONFIG = {\n",
    "        \"csv_path\": r'cvm_indicators_dataset_2011-2021.csv',\n",
    "        \"id_col\": \"ID\", \"quarter_col\": \"QUARTER\", \"target_col\": \"LABEL\",\n",
    "        \"meta_cols\": [\"ID\", \"QUARTER\", \"LABEL\"],\n",
    "        \"lags\": 4, \"seed\": 42,\n",
    "        \n",
    "        \"sliding_win_size\": 200,\n",
    "        \"retrain_interval\": 500,\n",
    "        \"optuna_trials\": 50,\n",
    "\n",
    "        \"lightgbm_expert_params\": {\n",
    "            \"objective\": \"binary\", \"metric\": \"auc\", \"random_state\": 42, \n",
    "            \"n_estimators\": 500, \"learning_rate\": 0.05, \"verbose\": -1,\n",
    "            \"scale_pos_weight\": 35 \n",
    "        },\n",
    "    }\n",
    "\n",
    "    champion_finder = LightGBM_Champion_Finder(config=CONFIG)\n",
    "    champion_finder.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8bed11-1cd8-412a-8470-9eb1e5b3961e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
