{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6166b9f7-d623-44ea-85da-34f0a190bffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "1. Loading and cleaning data...\n",
      "2. Preparing sequence data...\n",
      "\n",
      "3. Preparing data for SHAP analysis...\n",
      "   Training model on a snapshot of 3000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\gpu_env\\lib\\site-packages\\sklearn\\utils\\deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Setting up SHAP TreeExplainer...\n",
      "5. Calculating SHAP values...\n",
      "6. Generating SHAP summary plots...\n",
      "   âœ… Dot plot saved as 'shap_lgbm_summary_dot.png'\n",
      "   âœ… Bar plot saved as 'shap_lgbm_summary_bar.png'\n",
      "\n",
      "SHAP Analysis Complete!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "#\n",
    "# LightGBM SHAP Analysis - v2 (GPU-Accelerated & Robust)\n",
    "#\n",
    "from __future__ import annotations\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "class LightGBM_SHAP_Analysis:\n",
    "    def __init__(self, config: Dict[str, Any]):\n",
    "        self.config = config\n",
    "        self.df = self._load_data(config['csv_path'])\n",
    "        self.feat_cols = [c for c in self.df.columns if c not in config['meta_cols']]\n",
    "        self.X_all, self.y_all = self._make_windows()\n",
    "\n",
    "    def _load_data(self, path: str | Path) -> pd.DataFrame:\n",
    "        print(\"â”€\" * 60 + \"\\n1. Loading and cleaning data...\")\n",
    "        df = pd.read_csv(path).loc[:, ~pd.read_csv(path).columns.duplicated()]\n",
    "        req = set(self.config['meta_cols'])\n",
    "        if missing := req - set(df.columns): raise KeyError(f\"Missing cols: {missing}\")\n",
    "        df[self.config['quarter_col']] = pd.to_datetime(df[self.config['quarter_col']])\n",
    "        df.sort_values([self.config['id_col'], self.config['quarter_col']], inplace=True)\n",
    "        df = df.dropna()\n",
    "        return df\n",
    "\n",
    "    def _make_windows(self) -> (np.ndarray, np.ndarray):\n",
    "        print(\"2. Preparing sequence data...\")\n",
    "        X, y = [], []\n",
    "        cfg = self.config\n",
    "        for _, g in self.df.groupby(cfg['id_col']):\n",
    "            g = g.sort_values(cfg['quarter_col'])\n",
    "            arr, lbl = g[self.feat_cols].to_numpy(), g[cfg['target_col']].to_numpy()\n",
    "            for i in range(cfg['lags'], len(g)):\n",
    "                X.append(arr[i - cfg['lags']:i].ravel())\n",
    "                y.append(lbl[i])\n",
    "        return np.asarray(X), np.asarray(y)\n",
    "\n",
    "    def run_shap_analysis(self):\n",
    "        \"\"\"\n",
    "        Trains the champion LightGBM model on a recent data snapshot and\n",
    "        generates SHAP plots to explain its predictions.\n",
    "        \"\"\"\n",
    "        print(\"\\n3. Preparing data for SHAP analysis...\")\n",
    "        \n",
    "        n = len(self.y_all)\n",
    "        analysis_start_point = int(n * 0.6)\n",
    "        X_analysis, y_analysis = self.X_all[analysis_start_point:], self.y_all[analysis_start_point:]\n",
    "        \n",
    "        win_size = self.config['sliding_win_size']\n",
    "        X_train, y_train = X_analysis[-win_size:], y_analysis[-win_size:]\n",
    "        \n",
    "        if len(np.unique(y_train)) < 2:\n",
    "            print(\"âš ï¸  Initial window has only one class. Expanding backward...\")\n",
    "            extra_history = win_size\n",
    "            while len(np.unique(y_train)) < 2 and extra_history < len(X_analysis):\n",
    "                extra_history += win_size\n",
    "                X_train = X_analysis[-extra_history:]\n",
    "                y_train = y_analysis[-extra_history:]\n",
    "            print(f\"   Success! New training snapshot size: {len(y_train)}\")\n",
    "\n",
    "        print(f\"   Training model on a snapshot of {len(y_train)} samples.\")\n",
    "        \n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train_std = scaler.transform(X_train)\n",
    "        \n",
    "        champion_params = self.config['lgbm_champion_params']\n",
    "        model = lgb.LGBMClassifier(**champion_params).fit(X_train_std, y_train)\n",
    "        \n",
    "        print(\"\\n4. Setting up SHAP TreeExplainer...\")\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        \n",
    "        print(\"5. Calculating SHAP values...\")\n",
    "        shap_values = explainer.shap_values(X_train_std)\n",
    "        \n",
    "        print(\"6. Generating SHAP summary plots...\")\n",
    "        \n",
    "        # --- ðŸ”¥ FIX: Robustly handle SHAP value structure ---\n",
    "        # Check if shap_values is a list (for multi-class output) or a single array\n",
    "        if isinstance(shap_values, list) and len(shap_values) == 2:\n",
    "            # This is the expected case for binary classification\n",
    "            sv_to_plot = shap_values[1] # Use the values for the positive class (class 1)\n",
    "        elif isinstance(shap_values, np.ndarray) and shap_values.ndim == 2:\n",
    "            # This happens when TreeExplainer returns values for the positive class directly\n",
    "            sv_to_plot = shap_values\n",
    "        else:\n",
    "            raise TypeError(f\"Unexpected SHAP values structure: {type(shap_values)}\")\n",
    "\n",
    "        base_feat_names = self.feat_cols\n",
    "        lags = self.config['lags']\n",
    "        feature_names = [f\"{feat}_t-{i}\" for i in range(lags, 0, -1) for feat in base_feat_names]\n",
    "        \n",
    "        X_train_df = pd.DataFrame(X_train_std, columns=feature_names)\n",
    "        \n",
    "        # Generate and save the dot plot\n",
    "        shap.summary_plot(sv_to_plot, X_train_df, show=False)\n",
    "        plt.title(\"SHAP Summary for Optuna-Tuned LightGBM (Distress Class)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"shap_lgbm_summary_dot.png\", dpi=300)\n",
    "        plt.close()\n",
    "        print(\"   âœ… Dot plot saved as 'shap_lgbm_summary_dot.png'\")\n",
    "\n",
    "        # Generate and save the bar plot\n",
    "        shap.summary_plot(sv_to_plot, X_train_df, plot_type=\"bar\", show=False)\n",
    "        plt.title(\"Mean Absolute SHAP for Optuna-Tuned LightGBM\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"shap_lgbm_summary_bar.png\", dpi=300)\n",
    "        plt.close()\n",
    "        print(\"   âœ… Bar plot saved as 'shap_lgbm_summary_bar.png'\")\n",
    "        \n",
    "        print(\"\\nSHAP Analysis Complete!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    CONFIG = {\n",
    "        \"csv_path\": r'cvm_indicators_dataset_2011-2021.csv',\n",
    "        \"id_col\": \"ID\", \"quarter_col\": \"QUARTER\", \"target_col\": \"LABEL\",\n",
    "        \"meta_cols\": [\"ID\", \"QUARTER\", \"LABEL\"],\n",
    "        \"lags\": 4, \"seed\": 42,\n",
    "        \"sliding_win_size\": 3000, \n",
    "        \n",
    "        # Using the champion parameters discovered by Optuna for LightGBM\n",
    "        \"lgbm_champion_params\": {\n",
    "            \"objective\": 'binary',\n",
    "            \"metric\": 'auc',\n",
    "            \"random_state\": 42,\n",
    "            \"verbose\": -1,\n",
    "            # ðŸ”¥ Using GPU for acceleration\n",
    "            \"device\": 'gpu', \n",
    "            # Best values from your experiment results\n",
    "            'n_estimators': 400, \n",
    "            'learning_rate': 0.010268965803862608, \n",
    "            'num_leaves': 146, \n",
    "            'scale_pos_weight': 50\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # You might need to install shap, matplotlib, and a GPU-enabled lightgbm\n",
    "    # pip install shap matplotlib\n",
    "    # pip install lightgbm --config-settings=cmake.define.USE_GPU=ON\n",
    "    shap_analyzer = LightGBM_SHAP_Analysis(config=CONFIG)\n",
    "    shap_analyzer.run_shap_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d47493e-d6c7-4856-ad74-4d15a29ff9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
